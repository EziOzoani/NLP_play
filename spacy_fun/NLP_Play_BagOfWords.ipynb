{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Play-BagOfWords.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p44JGdoKJsS8"
      },
      "source": [
        "#**Bag of Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS02WGHmB-fZ"
      },
      "source": [
        "\n",
        "class Category:\n",
        "  BOOKS = \"BOOKS\"\n",
        "  CLOTHING = \"CLOTHING\"\n",
        "\n",
        "train_x = [\"i love the book\", \"this is a great book\", \"the fit is great\", \"i love the shoes\"]\n",
        "train_y = [Category.BOOKS, Category.BOOKS, Category.CLOTHING, Category.CLOTHING]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxLV3zuIJ0OW"
      },
      "source": [
        "\n",
        "**Fit vectoriser to transform text to bag-of-words vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4wdGd9TCF7b",
        "outputId": "f083360b-4154-4ce5-cd59-f8ab4947cacc"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# CountVectorizer can be either a binary bag of words [1,0]'s  or a straight count of a word in a sentence overall \n",
        "\n",
        "\n",
        "#Use countvectoriser to transform the tarin_x into vector representation \n",
        "#it fits a dictionary around the trainging train_x--> finds all the unquie words to make the vectors \n",
        "vectorizer = CountVectorizer(binary =True) #bianry=True : it keeps it as [1,0] even with repeats\n",
        "train_x_vectors =  vectorizer.fit_transform(train_x) #fit_transform: transforming the train_x passed, based on the vector that was just fitted \n",
        "\n",
        "# now get vectors \n",
        "#print(vectors[0])# vector[0]: will be vectors for \"i love the book\"\n",
        "print(vectorizer.get_feature_names())\n",
        "print(train_x_vectors.toarray())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']\n",
            "[[1 0 0 0 1 0 1 0]\n",
            " [1 0 1 1 0 0 0 1]\n",
            " [0 1 1 1 0 0 1 0]\n",
            " [0 0 0 0 1 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E-AjZDsJXLw"
      },
      "source": [
        "### Model to classify which sentences are clothing releated and which of them are book"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvdifcKdJRPD"
      },
      "source": [
        "**Train SVM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqriiTemGLa2",
        "outputId": "0bd3d732-3d85-4e20-8757-7c035d5b37db"
      },
      "source": [
        "# model to classify which sentences are clothing releated and which of them are book\n",
        "# Linear SVM is a good classic classification for text\n",
        "from sklearn import svm\n",
        "\n",
        "#clf_svm : classifier svm\n",
        "clf_svm = svm.SVC(kernel= 'linear') \n",
        "clf_svm.fit(train_x_vectors,train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjfObR3NJdKU"
      },
      "source": [
        "**Test new utterances on the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoCYMyEfHANL",
        "outputId": "33d37afe-90fb-41ac-c9f4-f7810c811595"
      },
      "source": [
        "#predict new uterances\n",
        "\n",
        "test_x = vectorizer.transform(['i like the book'])# tranform instead of fit transform as there is already a vectoriser\n",
        "\n",
        "clf_svm.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BOOKS'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDk2MtpMHiAR",
        "outputId": "1bce5757-521e-47d7-ebc0-292be3e72ae6"
      },
      "source": [
        "test_x = vectorizer.transform(['shoes are alright'])# tranform instead of fit transform as there is already a vectoriser\n",
        "\n",
        "clf_svm.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CLOTHING'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWL47DWvIOdB"
      },
      "source": [
        "### As the dictionary grows we get a more powerful model--> more training uterances the more powerful the model \n",
        "### If we have such a big dictionary that it could get harder to proecess the model \n",
        "    Could take the top e.g 1000 words that occur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0JyOa24JCC8"
      },
      "source": [
        "Currently doing a unigram approach: taking each indvidual word by itself \n",
        "Can also do Bi-gram approach: this would catorgise e.g \"i love the book\" as their own unquie uterances:  \"i love\", \"love the\", \"the book\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zorCjCm3JEGP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D9DxX3vJkoX"
      },
      "source": [
        "#**Word Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqitg1UuJocJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}